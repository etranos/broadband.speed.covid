---
title: "LAs_clusters"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: FALSE
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output")
  })
---

```{r settings, include = FALSE}
library(ggplot2)
library(tidyverse)
library(rprojroot)
library(lubridate)
library(knitr)
library(rprojroot)
library(nnet)
library(stargazer)
library(openair)
library(rgdal)
library(corrplot)
library(DescTools)
library(geosphere)

# This is the project path
path <- find_rstudio_root_file()
```

## Load cluster data

```{r include = FALSE}

# load the data created by Data_Spatial.Rmd and ts_clusters.Rmd
path.cluster <- paste(path, "/data/temp/clusters_nodiff.csv", sep = "")
clusters <- read_csv(path.cluster)
names(clusters) [1] <- "LAD19NM"

path.data <- paste(path, "/data/temp/TSbb19_20sp.csv", sep = "")
TSbb19_20sp <- read_csv(path.data)

#split out 2020 before join to clusters to create descriptives
TS2020 <- selectByDate(TSbb19_20sp, year = 2020) 
TS2019 <- selectByDate(TSbb19_20sp, year = 2019)

# LAD codes and names
# get LA 
# this is the heaviest version:
# (i) directly from the web
#la <- readOGR("http://geoportal1-ons.opendata.arcgis.com/datasets/b6d2e15801de45328b760a4f55d74318_0.geojson?outSR={%22latestWkid%22:3857,%22wkid%22:102100}")#, layer="OGRGeoJSON")
# or, (ii) from the json I saved locally
# path.json <- paste(path, "./data/raw/Local_Authority_Districts_(April_2019)_Boundaries_UK_BFE.geojson", sep = "")
# la <- readOGR(path.json)#, layer="OGRGeoJSON")
# UK BGC: 
la <- readOGR("https://opendata.arcgis.com/datasets/0e07a8196454415eab18c40a54dfbbef_0.geojson")
codes <- la@data %>%
  select(lad19cd, lad19nm) %>%
  rename(LAD19NM = lad19nm)

# LAD broadband characteristics AM
LAD.up.am19 <- TS2019 %>%
  filter(hour == 9 | hour == 10) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.up.am19 = mean(speedup))

LAD.up.am20 <- TS2020 %>%
  filter(hour == 9 | hour == 10) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.up.am20 = mean(speedup))

LAD.down.am19 <- TS2019 %>%
  filter(hour == 9 | hour == 10) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.down.am19 = mean(speeddown))

LAD.down.am20 <- TS2020 %>%
  filter(hour == 9 | hour == 10) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.down.am20 = mean(speeddown))

LAD.tests.am19 <- TS2019 %>%
  filter(hour == 9 | hour == 10) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.tests.am19 = n())

LAD.tests.am20 <- TS2020 %>%
  filter(hour == 9 | hour == 10) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.tests.am20 = n())

# LAD broadband characteristics PM
LAD.up.pm19 <- TS2019 %>%
  filter(hour == 19 | hour == 20) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.up.pm19 = mean(speedup))

LAD.up.pm20 <- TS2020 %>%
  filter(hour == 19 | hour == 20) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.up.pm20 = mean(speedup))

LAD.down.pm19 <- TS2019 %>%
  filter(hour == 19 | hour == 20) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.down.pm19 = mean(speeddown))

LAD.down.pm20 <- TS2020 %>%
  filter(hour == 19 | hour == 20) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.down.pm20 = mean(speeddown))

LAD.tests.pm19 <- TS2019 %>%
  filter(hour == 19 | hour == 20) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.tests.pm19 = n())

LAD.tests.pm20 <- TS2020 %>%
  filter(hour == 19 | hour == 20) %>%
  group_by(LAD19NM) %>%
  summarise(LAD.tests.pm20 = n())

# LAD characteristcs merge
lad <- list(codes,
            clusters,
            LAD.up.am19,
            LAD.up.am20,
            LAD.down.am19,
            LAD.down.am20,
            LAD.tests.am19,
            LAD.tests.am20,
            LAD.up.pm19,
            LAD.up.pm20,
            LAD.down.pm19,
            LAD.down.pm20,
            LAD.tests.pm19,
            LAD.tests.pm20)

sapply(lad, function(x) dim(x))
sapply(lad, function(x) sum(is.na(x)))

# merge with reduce
lad <- lad %>% 
  reduce(inner_join, by = "LAD19NM")
sapply(lad, function(x) sum(is.na(x)))
```

## Distance to Metro Area

```{r}
# get LA 
# (i) directly from the web
#la <- readOGR("http://geoportal1-ons.opendata.arcgis.com/datasets/b6d2e15801de45328b760a4f55d74318_0.geojson?outSR={%22latestWkid%22:3857,%22wkid%22:102100}")#, layer="OGRGeoJSON")
# or, (ii) from the json I saved locally
path.json <- paste(path, "./data/raw/Local_Authority_Districts_(April_2019)_Boundaries_UK_BFE.geojson", sep = "")
la <- readOGR(path.json)#, layer="OGRGeoJSON")
# source: https://data.gov.uk/dataset/7c387c64-d25f-474a-b07e-b933578caea2/local-authority-districts-april-2019-boundaries-uk-bfe

# spatial transformations
la <- spTransform(la, CRS("+init=epsg:4326"))
la@data$LAD19NM <- as.character(la@data$LAD19NM)
ladDist <- la@data[,c("LAD19CD", "LAD19NM")]
names(ladDist)[1] <- "lad19cd"

#distance from London and other 
coords_LAD <- la@data[,c("LONG", "LAT")]
London <- la[which(la@data$LAD19NM == "City of London"),]
London <- gCentroid(London)
distLondon <- distm(coords_LAD, London, fun=distCosine) 
#result in meters - change to km
distLondon <- round((distLondon/1000),2)
Birmingham <- la[which(la@data$LAD19NM == "Birmingham"),]
Birmingham <- gCentroid(Birmingham)
distBham <- distm(coords_LAD, Birmingham, fun=distCosine)
distBham <- round((distBham/1000),2)
Manchester <- la[which(la@data$LAD19NM == "Manchester"),]
Manchester <- gCentroid(Manchester)
distManc <- distm(coords_LAD, Manchester, fun=distCosine)
distManc <- round((distManc/1000),2)
Leeds <- la[which(la@data$LAD19NM == "Leeds"),]
Leeds <- gCentroid(Leeds)
distLeeds <- distm(coords_LAD, Leeds, fun=distCosine)
distLeeds <- round((distLeeds/1000),2)
Liverpool <- la[which(la@data$LAD19NM == "Liverpool"),]
Liverpool <- gCentroid(Liverpool)
distLivp <- distm(coords_LAD, Liverpool, fun=distCosine)
distLivp <- round((distLivp/1000),2)
Newcastle <- la[which(la@data$LAD19NM == "Newcastle upon Tyne"),]
Newcastle <- gCentroid(Newcastle)
distNewc <- distm(coords_LAD, Newcastle, fun=distCosine)
distNewc <- round((distNewc/1000),2)
Sheffield <- la[which(la@data$LAD19NM == "Sheffield"),]
Sheffield <- gCentroid(Sheffield)
distShef <- distm(coords_LAD, Sheffield, fun=distCosine)
distShef <- round((distShef/1000),2)
SouthHants <- la[which(la@data$LAD19NM == "Fareham"),]
SouthHants <- gCentroid(SouthHants)
distSHam <- distm(coords_LAD, SouthHants, fun=distCosine)
distSHam <- round((distSHam/1000),2)
Nottingham <- la[which(la@data$LAD19NM == "Nottingham"),]
Nottingham <- gCentroid(Nottingham)
distNotts <- distm(coords_LAD, Nottingham, fun=distCosine)
distNotts <- round((distNotts/1000),2)
Bristol <- la[which(la@data$LAD19NM == "Bristol, City of"),]
Bristol <- gCentroid(Bristol)
distBris <- distm(coords_LAD, Bristol, fun=distCosine)
distBris <- round((distBris/1000),2)
Cardiff <- la[which(la@data$LAD19NM == "Cardiff"),]
Cardiff <- gCentroid(Cardiff)
distCard <- distm(coords_LAD, Cardiff, fun=distCosine)
distCard <- round((distCard/1000),2)
Glasgow <- la[which(la@data$LAD19NM == "Glasgow City"),]
Glasgow <- gCentroid(Glasgow)
distGlas <- distm(coords_LAD, Glasgow, fun=distCosine) 
distGlas <- round((distGlas/1000),2)

ladDist <- cbind(ladDist, distLondon, distBham, distManc, distLeeds,
                 distLivp, distNewc, distShef, distSHam, distNotts, 
                 distBris, distCard, distGlas)

ladDist$distMet <- apply(ladDist[,3:14], 1, min)

#test <- left_join(lad, ladDist)
```

## Job density

```{r}
job.dens <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_57_1.data.csv?geography=1816133633...1816133848,1820327937...1820328318&date=latest&item=3&measures=20100")

job.dens <- job.dens %>%
  dplyr::select(GEOGRAPHY_CODE, GEOGRAPHY_NAME, OBS_VALUE) %>%
  rename(job.dens2018 = OBS_VALUE) %>%
  rename(lad19cd = GEOGRAPHY_CODE) %>%
  distinct()

# test <- left_join(lad, job.dens, by = "lad19cd")
```

## Population

```{r}
pop <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_31_1.data.csv?geography=1807745025...1807745028,1807745030...1807745032,1807745034...1807745155,1807745157...1807745164,1807745166...1807745170,1807745172...1807745177,1807745179...1807745194,1807745196,1807745197,1807745199,1807745201...1807745218,1807745221,1807745222,1807745224,1807745226...1807745231,1807745233,1807745234,1807745236...1807745244,1807745271...1807745281,1811939329...1811939332,1811939334...1811939336,1811939338...1811939497,1811939499...1811939501,1811939503,1811939505...1811939507,1811939509...1811939517,1811939519,1811939520,1811939524...1811939570,1811939575...1811939599,1811939601...1811939628,1811939630...1811939634,1811939636...1811939647,1811939649,1811939655...1811939664,1811939667...1811939680,1811939682,1811939683,1811939685,1811939687...1811939704,1811939707,1811939708,1811939710,1811939712...1811939717,1811939719,1811939720,1811939722...1811939730,1811939757...1811939767&date=latestMINUS1-latest&sex=7&age=0,22&measures=20100")

pop <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_31_1.data.csv?geography=1820327937...1820328318,1816133633...1816133848&date=latestMINUS1-latest&sex=7&age=0,22&measures=20100")

pop <- pop %>%
  dplyr::select(GEOGRAPHY_CODE, GEOGRAPHY_NAME, AGE_NAME, OBS_VALUE) %>%
  distinct(GEOGRAPHY_CODE, AGE_NAME, .keep_all = T) %>% 
  spread(AGE_NAME, OBS_VALUE) %>% 
  rename(pop16_64 = `Aged 16 - 64`) %>%
  rename(pop = `All ages`) %>%
  rename(lad19cd = GEOGRAPHY_CODE)

# test <- left_join(lad, pop, by = "lad19cd")
# sapply(test, function(x) sum(is.na(x)))
```

## Labour supply

```{r}
labour <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_17_5.data.csv?geography=1816133633...1816133837,1820327937...1820328307&date=latest&variable=18,1532...1540,290,720&measures=20599,21001,21002,21003")

labour <- labour %>%
  dplyr::select(GEOGRAPHY_CODE, GEOGRAPHY_NAME, VARIABLE_NAME, OBS_VALUE) %>%
  distinct(GEOGRAPHY_CODE, VARIABLE_NAME, .keep_all = T) %>% 
  spread(VARIABLE_NAME, OBS_VALUE) %>% 
  rename(lad19cd = GEOGRAPHY_CODE) %>%
  rename(managers =  `% all in employment who are - 1: managers, directors and senior officials (SOC2010)`) %>%
  rename(prof = `% all in employment who are - 2: professional occupations (SOC2010)`) %>%
  rename(tech = `% all in employment who are - 3: associate prof & tech occupations (SOC2010)`) %>%
  rename(admin = `% all in employment who are - 4: administrative and secretarial occupations (SOC2010)`) %>%
  rename(skilled = `% all in employment who are - 5: skilled trades occupations (SOC2010)`) %>%
  rename(caring = `% all in employment who are - 6: caring, leisure and other service occupations (SOC2010)`) %>%
  rename(sales = `% all in employment who are - 7: sales and customer service occupations (SOC2010)`) %>%
  rename(plant = `% all in employment who are - 8: process, plant and machine operatives (SOC2010)`) %>%
  rename(elementary = `% all in employment who are - 9: elementary occupations (SOC2010)`) %>%
  rename(NVQ3 = `% with NVQ3+ - aged 16-64`) %>%
  rename(NVQ4 = `% with NVQ4+ - aged 16-64`) %>%
  rename(econ.act = `Economic activity rate - aged 16-64`)

# test <- left_join(lad, labour, by = "lad19cd")
# sapply(test, function(x) sum(is.na(x)))
```

## Earnings

```{r}
earnings <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_30_1.data.csv?geography=1946157348,2092957698,2013265929,1816133633...1816133837,1820327937...1820328307&date=latest&sex=8&item=2&pay=1&measures=20100,20701")

earnings <- earnings %>%
  filter(MEASURES_NAME == "Value") %>% # dropiing the confedence
  dplyr::select(GEOGRAPHY_CODE, GEOGRAPHY_NAME, OBS_VALUE) %>%
  rename(lad19cd = GEOGRAPHY_CODE) %>%
  rename(earnings =  OBS_VALUE) %>%
  distinct()

# test <- left_join(lad, earnings, by = "lad19cd")
# sapply(test, function(x) sum(is.na(x)))
```

## Business counts

```{r}
# busi <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_141_1.data.csv?geography=1816133633...1816133848,1820327937...1820328318,1870659585...1870659791,1870659801,1870659792...1870659800,1879048193...1879048573,1879048583,1879048574...1879048582&date=latest&industry=163577857...163577874&employment_sizeband=0&legal_status=0&measures=20100")

busi <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_141_1.data.csv?geography=1816133633...1816133848,1820327937...1820328318,1870659585...1870659791,1870659801,1870659792...1870659800,1879048193...1879048573,1879048583,1879048574...1879048582&date=latest&industry=150994945...150994965&employment_sizeband=0&legal_status=0&measures=20100")

busi <- busi %>%
  dplyr::select(GEOGRAPHY_CODE, GEOGRAPHY_NAME, INDUSTRY_NAME, OBS_VALUE) %>%
  distinct(GEOGRAPHY_CODE, INDUSTRY_NAME, .keep_all = T) %>% 
  spread(INDUSTRY_NAME, OBS_VALUE) %>% 
  rename(lad19cd = GEOGRAPHY_CODE) %>%
  rename(A = `A : Agriculture, forestry and fishing`) %>%
  rename(B = `B : Mining and quarrying`) %>%
  rename(C = `C : Manufacturing`) %>%
  rename(D = `D : Electricity, gas, steam and air conditioning supply`) %>%
  rename(E = `E : Water supply; sewerage, waste management and remediation activities`) %>%
  rename(F = `F : Construction`) %>%
  rename(G = `G : Wholesale and retail trade; repair of motor vehicles and motorcycles`) %>%
  rename(H = `H : Transportation and storage`) %>%
  rename(I = `I : Accommodation and food service activities`) %>%
  rename(J = `J : Information and communication`) %>%
  rename(K = `K : Financial and insurance activities`) %>%
  rename(L = `L : Real estate activities`) %>%
  rename(M = `M : Professional, scientific and technical activities`) %>%
  rename(N = `N : Administrative and support service activities`) %>%
  rename(O = `O : Public administration and defence; compulsory social security`) %>%
  rename(P = `P : Education`) %>%
  rename(Q = `Q : Human health and social work activities`) %>%
  rename(R = `R : Arts, entertainment and recreation`) %>%
  rename(S = `S : Other service activities`) %>%
  rename(T = `T : Activities of households as employers;undifferentiated goods-and services-producing activities of households for own use`) %>%
  rename(U = `U : Activities of extraterritorial organisations and bodies`) %>%
  mutate(total.busi = rowSums(.[3:23]))

# test <- left_join(lad, busi, by = "lad19cd")
# sapply(test, function(x) sum(is.na(x)))
```

## merge

```{r}
data <- list(lad, job.dens, pop, labour, earnings, busi)
sapply(data, function(x) dim(x))
sapply(data, function(x) names(x))

# merge with reduce
data <- data %>% 
  reduce(inner_join, by = "lad19cd") %>%
  #distinct(.keep_all = T)
  unique()
sapply(data, function(x) sum(is.na(x)))
```

## Descriptive statistics and correlations

There is surprisingly low correlation between upload and download, morning and night. 
Number of tests are the most correlated variables.

```{r correlations}
data.cor <- data %>%
  dplyr::select(LAD.up.am19, LAD.down.am19,  
                LAD.tests.am19, LAD.up.pm19, 
                LAD.down.pm19, LAD.tests.pm19, 
                LAD.up.am20, LAD.down.am20,
                LAD.tests.am20, LAD.up.pm20, 
                LAD.down.pm20, LAD.tests.pm20)

m <- cor(data.cor)
corrplot(m, type="upper",method = "number", number.cex = .5, tl.cex = .75)

data.cor <- data %>%
  dplyr::select(LAD.up.am20, LAD.up.pm20,
                LAD.tests.pm20,
                pop, pop16_64,
                managers, tech,
                skilled, earnings,
                total.busi)

m <- cor(data.cor, use = "pairwise.complete.obs")
corrplot(m, type="upper",method = "number", number.cex = .5, tl.cex = .75)
```

## Auxiliary regression, dep. var.: upload clusters

```{r upload regression, results= 'asis', message=F, error=F, warning=F}
# helpful sources: http://www.princeton.edu/~otorres/LogitR101.pdf
# https://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/

aux <- multinom(cluster.up ~ LAD.up.am20 + LAD.up.pm20 + LAD.tests.pm20 + #  LAD.down.am20 + LAD.down.pm20
                   pop + pop16_64 + # how about young population share
                   managers + tech + skilled +
                   earnings + total.busi, data = data, 
                trace = F) # to avoid messages 

# McFadden's R squared
aux.null <- multinom(cluster.up ~ 1, data = data)
r2 <- 1-logLik(aux)/logLik(aux.null)

stargazer(aux, type = "html",
          add.lines = list(c("McFadden's R squared",                    # use rownames as line name. in this case Weak insterumetns
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3))))

```

## Auxiliary regression, dep. var.: upload clusters, without upload variables

```{r upload regression no upload and test, results= 'asis', message=F, error=F, warning=F}
# helpful sources: http://www.princeton.edu/~otorres/LogitR101.pdf
# https://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/

aux <- multinom(cluster.up ~ pop + pop16_64 + # how about young population share
                  managers + tech + skilled +
                  earnings + total.busi, data = data, 
                trace = F) # to avoid messages 

# McFadden's R squared
aux.null <- multinom(cluster.up ~ 1, data = data)
r2 <- 1-logLik(aux)/logLik(aux.null)

stargazer(aux, type = "html",
          add.lines = list(c("McFadden's R squared",                    # use rownames as line name. in this case Weak insterumetns
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3))))

```

## Auxiliary regression, dep. var.: download clusters

```{r download regression, results= 'asis', message=F, error=F, warning=F}
# helpful sources: http://www.princeton.edu/~otorres/LogitR101.pdf
# https://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/

aux <- multinom(cluster.down ~ LAD.down.am20 + LAD.down.pm20 + LAD.tests.pm20 + #  LAD.down.am20 + LAD.down.pm20
                   pop + pop16_64 + # how about young population share
                   managers + tech + skilled +
                   earnings + total.busi, data = data, 
                trace = F) # to avoid messages 

# McFadden's R squared
aux.null <- multinom(cluster.down ~ 1, data = data)
r2 <- 1-logLik(aux)/logLik(aux.null)

stargazer(aux, type = "html",
          add.lines = list(c("McFadden's R squared",                    # use rownames as line name. in this case Weak insterumetns
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3), round(r2[1],3), round(r2[1],3),
                              round(r2[1],3))))

```