---
title: "Time series plots"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output")
  })
---

```{r settings, include = FALSE}
library(tsbox)
library(ggplot2)
library(tidyverse)
library(geojsonio)
library(tsfeatures)
library(rprojroot)
library(openair)
library(reshape2)
library(lubridate)
library(rgdal)
library(maptools)
library(sp)
library(rgeos)
library(classInt)
library(RColorBrewer)
library(knitr)
library(rprojroot)
library(viridis)
library(hrbrthemes)

# This is the project path
path <- find_rstudio_root_file()
```

```{r include = FALSE}

# load and clean the data.
# copied from bbData2020.Rmd

#upload data file
path.data <- paste(path, "./data/raw/speedtest.csv", sep = "")

#bb2020 <- read.csv("./data/raw/speedtest.csv")
bb2020 <- read.csv(path.data)

#name columns
names(bb2020)[1:6] <- c("datetext","speeddown","speedup","provider","lat", "lon") 

str(bb2020)
summary(bb2020) #2030205 obs
#conversions needed to numeric? df$col <- as.numeric(df$col) 
#remove empty rows or coerced to NA? df[complete.cases(df),] or df <- df[!is.na(df$col),]

#remove outliers based on Riddlesden and Singleton 2014 for slower end
#check fastest upload and download speeds commercially available from Virgin Media (Gigaclear offers even faster!)
bb2020 <- bb2020[bb2020$speeddown>512,] 
bb2020 <- bb2020[bb2020$speeddown<362000,]
bb2020 <- bb2020[bb2020$speedup<21000,] #1839333

#remove below seconds, create columns for date and hour
bb2020$datetext <- strtrim(x = bb2020$datetext, width = 19) 
bb2020$datetext2 <- bb2020$datetext
bb2020$datetext2 <- strtrim(x = bb2020$datetext2, width = 13)
bb2020$datetext2 <- colsplit(bb2020$datetext2, pattern = " ", c("date", "hour"))
bb2020$hour <- bb2020$datetext2$hour
bb2020$date <- bb2020$datetext2$date
#delete datetext2 column(s)
bb2020 <- bb2020[ ,c(1:6,8:9)]
#convert to date form datetext and date columns
bb2020$datetext <- as.POSIXct(strptime(bb2020$datetext, format = "%Y-%m-%d %H:%M:%S", "GMT")) 
bb2020$date <- as.POSIXct(strptime(bb2020$date, format = "%Y-%m-%d", "GMT"))
#create dataframe with number of tests, mean and standard deviation by month for adding to dataframe later
MonthFreq <- timeAverage(bb2020, avg.time = "month", statistic = "frequency")
MonthMean <- timeAverage(bb2020, avg.time = "month", statistic = "mean")
MonthSD <- timeAverage(bb2020, avg.time = "month", statistic = "sd")
MonthStats <- cbind(MonthFreq[,1:2], MonthMean[,c(3:4)], 
                    MonthSD[,c(3:4)])
names(MonthStats) <- c("month", "monthlyTests", "monthlyMeanSpDown", 
                       "monthlyMeanSpUp", "monthlySDSpDown", 
                       "monthlySDSpUp")
MonthStats$month <- month(MonthStats$month, label = TRUE, abbr = TRUE)
#add column for month and day of the week to create stats below
bb2020$month <- month(bb2020$date, label = TRUE, abbr = TRUE)
bb2020$weekday <- wday(bb2020$date, label = TRUE)
#divide MonthStats for future join with separate 2019 and 2020 dataframes
MonthStats19 <- MonthStats[1:6,]
MonthStats20 <- MonthStats[13:17,]
```

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=10, fig.width=10}

# Structured TS

# convert to spatial object
coords_bb <- cbind(bb2020$lon, bb2020$lat)
bb.la <- SpatialPointsDataFrame(coords_bb, data = data.frame(bb2020))
proj4string(bb.la) <- CRS("+init=epsg:4326") #define projection

# get LA 
# (i) directly from the web
#la <- readOGR("http://geoportal1-ons.opendata.arcgis.com/datasets/b6d2e15801de45328b760a4f55d74318_0.geojson?outSR={%22latestWkid%22:3857,%22wkid%22:102100}")#, layer="OGRGeoJSON")
# or, (ii) from the json I saved locally
path.json <- paste(path, "./data/raw/Local_Authority_Districts_(April_2019)_Boundaries_UK_BFE.geojson", sep = "")
la <- readOGR(path.json)#, layer="OGRGeoJSON")
# UK BGC la <- readOGR("https://opendata.arcgis.com/datasets/0e07a8196454415eab18c40a54dfbbef_0.geojson")
# UK BFC la <- readOGR("https://opendata.arcgis.com/datasets/1d78d47c87df4212b79fe2323aae8e08_0.geojson") 

# source: https://data.gov.uk/dataset/7c387c64-d25f-474a-b07e-b933578caea2/local-authority-districts-april-2019-boundaries-uk-bfe

# spatial transformations
la <- spTransform(la, CRS("+init=epsg:4326"))
la@data$LAD19NM <- as.character(la@data$LAD19NM)

# spatial join to LAD
bb.la.sp <- over(bb.la, la[, "LAD19NM"]) #not a spatial object
bb.la$LAD19NM <- bb.la.sp$LAD19NM

# create dataframe object to analyse (remove lat and lon?)
bb2020sp <- bb.la@data

# drop NAs
bb2020sp <- bb2020sp[!is.na(bb2020sp$LAD19NM),]
#13431/1839332 = .0073 NA LAD19NM, coord outside UK

# summarise by date and geography
la.date.count <- count(bb2020sp, LAD19NM, date)
la.dateAvg <- summarise(group_by(la.date.count, LAD19NM), mean(n))
range(la.dateAvg$`mean(n)`)

# map LA mean test frequency per date
la@data <- left_join(la@data, la.dateAvg, by = "LAD19NM")
var <- la@data[ ,'mean(n)']
breaks <- classIntervals(var, n = 5, style = "quantile")
my_colours <- brewer.pal(5, "Blues")
plot(la, col = my_colours[findInterval(var, breaks$brks, all.inside = TRUE)], axes = FALSE,
                 border = rgb(0.8, 0.8, 0.8, 0))
# drop LA
rm(la)
```

## Sub-daily timeseries

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}

bb2020sp <- bb2020sp %>% arrange(datetext)

# create sub daily blocks
bb2020sp$block[bb2020sp$hour>=0 & bb2020sp$hour<8] <- 1
bb2020sp$block[bb2020sp$hour>=8 & bb2020sp$hour<16] <- 2
bb2020sp$block[bb2020sp$hour>=16 & bb2020sp$hour<24] <- 3

#bb2020sp$date.block <- paste(bb2020sp$date, bb2020sp$date.block, sep = "_")
# I use block as hour for the ts_wide()
bb2020sp$date.block = ymd_h(paste(bb2020sp$date, bb2020sp$block))

head(bb2020sp)
```

## Download speeds

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}
ts.down <- bb2020sp %>%
  group_by(date.block,LAD19NM) %>%
  summarise(mean.down = mean(speeddown))#, mean.down = mean(speeddown), n.tests = n())
sapply(ts.down, function(x) sum(is.na(x)))


# https://www.data-to-viz.com/caveat/spaghetti.html

mean.down.uk <- ts.down %>%
  group_by(date.block) %>%
  summarise(mean.down.uk = mean(mean.down))#, mean.down = mean(speeddown), n.tests = n())

start.date =  "2019-12-31" 

ggplot(subset(ts.down,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.down, group = LAD19NM, colour = "red")) +
  geom_line() + guides(colour=FALSE) + ggtitle("Download speeds") + #xlab("") +
  ylab("download speed") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~LAD19NM, ncol = 2) +
  geom_line(data = subset(mean.down.uk,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.down.uk, group = 1), colour="green") #

```

## Upload speeds

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}
ts.up <- bb2020sp %>%
  group_by(date.block,LAD19NM) %>%
  summarise(mean.up = mean(speedup))
sapply(ts.up, function(x) sum(is.na(x)))


# https://www.data-to-viz.com/caveat/spaghetti.html

mean.up.uk <- ts.up %>%
  group_by(date.block) %>%
  summarise(mean.up.uk = mean(mean.up))

start.date =  "2019-12-31" 

ggplot(subset(ts.up,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.up, group = LAD19NM, colour = "red")) +
  geom_line() + guides(colour=FALSE) + ggtitle("Upload speeds") + #xlab("") +
  ylab("upload speed") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~LAD19NM, ncol = 2) +
  geom_line(data = subset(mean.up.uk,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.up.uk, group = 1), colour="green") #

```

## Speed tests

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}
ts.tests <- bb2020sp %>%
  group_by(date.block,LAD19NM) %>%
  summarise(n.tests = n())
sapply(ts.tests, function(x) sum(is.na(x)))


# https://www.data-to-viz.com/caveat/spaghetti.html

# n.tests.uk <- ts.tests %>%
#   group_by(date.block) %>%
#   summarise(n.tests = n()/382)

mean.tests.uk <- ts.tests %>%
  group_by(date.block) %>%
  summarise(mean.tests.uk = mean(n.tests))


start.date =  "2019-12-31" 

ggplot(subset(ts.tests,date.block > start.date), aes(x=as.POSIXct(date.block), y=n.tests, group = LAD19NM, colour = "red")) +
  geom_line() + guides(colour=FALSE) + ggtitle("N. of tests") + #xlab("") +
  ylab("tests") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~LAD19NM, ncol = 2, scales = "free_y") +
  geom_line(data = subset(mean.tests.uk,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.tests.uk, group = 1), colour="green") #.uk

```

## Download diff 2020 - 2019

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}

ts.down.diff <- ts.down
ts.down.diff$date.block.lag1y <- ts.down.diff$date.block - years(1)
ts.down.diff <- merge(ts.down.diff,ts.down.diff, by.x = c("date.block.lag1y", "LAD19NM"), by.y = c("date.block","LAD19NM"), all = F)

ts.down.diff <- ts.down.diff %>%
  rename(mean.down2019 = mean.down.y, mean.down2020 = mean.down.x) %>%
  select(-date.block.lag1y.y)

ts.down.diff$diff <- ts.down.diff$mean.down2020 - ts.down.diff$mean.down2019

head(ts.down.diff)
sapply(ts.down.diff, function(x) sum(is.na(x)))

# https://www.data-to-viz.com/caveat/spaghetti.html

mean.down.diff.uk <- ts.down.diff %>%
  group_by(date.block) %>%
  summarise(mean.down.diff.uk = mean(diff))#, mean.down = mean(speeddown), n.tests = n())

start.date =  "2019-12-31" 

ggplot(subset(ts.down.diff,date.block > start.date), aes(x=as.POSIXct(date.block), y=diff, group = LAD19NM, colour = "red")) +
  geom_line() + guides(colour=FALSE) + ggtitle("Diff. in download speeds") + #xlab("") +
  ylab("diff. in download speed") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~LAD19NM, ncol = 2) +
  geom_line(data = subset(mean.down.uk,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.down.uk, group = 1), colour="green") #
```

## Upload diff 2020 - 2019

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}

ts.up.diff <- ts.up
ts.up.diff$date.block.lag1y <- ts.up.diff$date.block - years(1)
ts.up.diff <- merge(ts.up.diff,ts.up.diff, by.x = c("date.block.lag1y", "LAD19NM"), by.y = c("date.block","LAD19NM"), all = F)

ts.up.diff <- ts.up.diff %>%
  rename(mean.up2019 = mean.up.y, mean.up2020 = mean.up.x) %>%
  select(-date.block.lag1y.y)

ts.up.diff$diff <- ts.up.diff$mean.up2020 - ts.up.diff$mean.up2019

head(ts.up.diff)
sapply(ts.up.diff, function(x) sum(is.na(x)))

# https://www.data-to-viz.com/caveat/spaghetti.html

mean.up.diff.uk <- ts.up.diff %>%
  group_by(date.block) %>%
  summarise(mean.up.diff.uk = mean(diff))#, mean.up = mean(speedup), n.tests = n())

start.date =  "2019-12-31" 

ggplot(subset(ts.up.diff,date.block > start.date), aes(x=as.POSIXct(date.block), y=diff, group = LAD19NM, colour = "red")) +
  geom_line() + guides(colour=FALSE) + ggtitle("Diff. in upload speeds") + #xlab("") +
  ylab("diff. in upload speed") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~LAD19NM, ncol = 2) +
  geom_line(data = subset(mean.up.diff.uk,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.up.diff.uk, group = 1), colour="green") #
```


## Speed tests diff. 2020 - 2019

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=600, fig.width=14}
ts.tests.diff <- ts.tests
ts.tests.diff$date.block.lag1y <- ts.tests.diff$date.block - years(1)
ts.tests.diff <- merge(ts.tests.diff,ts.tests.diff, by.x = c("date.block.lag1y", "LAD19NM"), by.y = c("date.block","LAD19NM"), all = F)

ts.tests.diff <- ts.tests.diff %>%
  rename(n.tests2019 = n.tests.y, n.tests2020 = n.tests.x) %>%
  select(-date.block.lag1y.y)

ts.tests.diff$diff <- ts.tests.diff$n.tests2020 - ts.tests.diff$n.tests2019

head(ts.tests.diff)
sapply(ts.tests.diff, function(x) sum(is.na(x)))

mean.tests.diff.uk <- ts.tests.diff %>%
  group_by(date.block) %>%
  summarise(mean.tests.diff.uk = mean(diff))

start.date =  "2019-12-31" 

ggplot(subset(ts.tests.diff,date.block > start.date), aes(x=as.POSIXct(date.block), y=diff, group = LAD19NM, colour = "red")) +
  geom_line() + guides(colour=FALSE) + ggtitle("Diff. in speed tests") + #xlab("") +
  ylab("diff. in speed tests") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~LAD19NM, ncol = 2) +
  geom_line(data = subset(mean.tests.diff.uk,date.block > start.date), aes(x=as.POSIXct(date.block), y=mean.tests.diff.uk, group = 1), colour="green") #
```